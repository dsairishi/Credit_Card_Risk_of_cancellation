---
title: "Machine Learning Project"
---


**Your Name**: DENDUKURI SAI RISHI VARMA
**Your G Number**:G01269219



```{r warning = FALSE, message = FALSE}
# Suppress dplyr summarise grouping warning messages
options(dplyr.summarise.inform = FALSE)
library(MASS)
library(tidyverse)
library(tidymodels)
library(yardstick)

credit_card_df <- readRDS(url('https://gmubusinessanalytics.netlify.app/data/credit_card_df.rds'))

# Checking the positive class
levels(credit_card_df$customer_status)

```



# Data Analysis

In this section, you must think of at least 5 relevant questions that explore the relationship between `customer_status` and the other variables in the `credit_card_df` data set. The goal of your analysis should be discovering which variables drive the differences between customers who do and do not close their account.

You must answer each question and provide supporting data summaries with either a summary data frame (using `dplyr`/`tidyr`) or a plot (using `ggplot`) or both.

In total, you must have a minimum of 3 plots (created with `ggplot`) and 3 summary data frames (created with `dplyr`) for the exploratory data analysis section. Among the plots you produce, you must have at least 3 different types (ex. box plot, bar chart, histogram, scatter plot, etc...)

See the [Data Analysis Project](https://gmubusinessanalytics.netlify.app/data-analysis-project.html){target="_blank"} for an example of a question answered with a summary table and plot.

**Note**: To add an R code chunk to any section of your project, you can use the keyboard shortcut `Ctrl` + `Alt` + `i` or the `insert` button at the top of your R project template notebook file.



# Question 1


**Question**:
Does last year transactions effect the customer status ?

**Answer**:
The table below shows average transactions made last year between customers who closed credit cards and those who have active accounts. The average transactions made last year is higher for active status class than closed status class. This means people who made more transactions are more likely to maintain active status.    

```{r}
head(credit_card_df)

#Count of entries in each class. 
credit_card_df_classes <- credit_card_df %>% 
  group_by(customer_status) %>% 
  summarise(Total_entries = length(customer_status))

#Data Frame.
credit_card_df_classes

#Summary dataframe for last year spending
credit_card_df_transactions <- credit_card_df %>% 
  group_by(customer_status) %>% 
  summarise(Avg_trans = mean(transactions_last_year),
            max_no_trans = max(transactions_last_year),
            min_no_trans = min(transactions_last_year)
            )

credit_card_df_transactions



#Visulaization
ggplot(data = credit_card_df_transactions, mapping = aes(x = customer_status, y = Avg_trans)) +
       geom_bar(stat = "identity", fill = "steelblue" ) +
       geom_text( aes(label=Avg_trans), color = "White" , vjust= 2) +
       labs(title = "Average Number of transactions in each class",
       x = "Customer Status",
       y = "Average Number of transactions") +
  theme(plot.title=element_text(hjust=0.5)) +
  theme_minimal()
  

```



# Question 2


**Question**:
Does last year spendings make any difference in account ?
**Answer**:
The table below shows average spendings made last year between customer who closed credit cards and those who have active accounts. The average spendings made last year is higher for active status class than closed status class. This means people who made more spendings are more likely to maintain active status.

```{r}
head(credit_card_df)

#Summary Data Frame showing  average last year spending between each class pf customer status.
credit_card_df_spending <- credit_card_df %>% 
  group_by(customer_status) %>% 
  summarise(avg_spendings_last_year = mean(total_spend_last_year),
            max_spending = max(total_spend_last_year),
            min_spending = min(total_spend_last_year)
            )

#Visualization Data Frame.
ggplot(data = credit_card_df_spending, mapping = aes(x = customer_status, y = avg_spendings_last_year)) +
       geom_bar(stat = "identity", color="red", fill="white" ) +
       geom_text( aes(label=avg_spendings_last_year), color = "Black" , vjust= 2) +
       labs(title = "Average spendings last year",
       x = "Customer Status",
       y = "Average spendings last year") +
  theme(plot.title=element_text(hjust=0.5))

```


# Question 3


**Question**:
Does number of dependents effect the people who have closed the account ?

**Answer**:
The below graph shows the total count of rows in each number of dependents category. We can see there are most people having 3 dependents in the closed account category followed by people having 2 dependents. This means that having more dependents might not be the reason for a person to close the account.   

```{r}

# Filtering rows having closed status. 
credit_card_df_closed <- credit_card_df %>% filter(customer_status == "closed_account")

credit_card_df_closed

#Summary table
credit_card_df_dependents <- credit_card_df_closed %>% 
  group_by(dependents) %>% 
  summarise(Total = length(dependents), avg_salary = mean(income), medain_salary = median(income))

credit_card_df_dependents

#Visualization
ggplot(data = credit_card_df_dependents, mapping = aes(x = dependents, y = Total)) +
       geom_line(color = "#0072B2") +
       geom_point() +
       geom_text(nudge_y = -3, nudge_x = -0.2, size=2.5, aes(label = Total)) +
       labs(title = "Count of Dependents for 'Closed account' status",
           x = "Dependents", y = "Total_number_of_dependents") +
  theme(plot.title=element_text(hjust=0.5))




```



# Question 4


**Question**:
Is credit limit affecting the closure status ?

**Answer**:
The figure below shows the box plots corresponding to closure status and credit limit. Box plots present five summary statistics for a continuous variable (median, two hinge points, and two whiskers) as well as all "outlying points." From the summary table, we can see that credit limit is high for active accounts when compared to closed accounts. Similarly, active accounts have higher median value when compared to closed accounts . We can infer that higher credit limits will impact closure status of a person. 

```{r}
#Summary Table
credit_card_df %>% group_by(customer_status) %>% 
                  summarise(Median_credit_limit = median(credit_limit),
                            avg_credit_limit = mean(credit_limit))
                            


#Visulaization
ggplot(data = credit_card_df, mapping = aes(x = customer_status , y = credit_limit, fill = customer_status)) +
  geom_boxplot() +
  scale_y_continuous(breaks = seq(0, 20000, 2000), limits = c(0,25000) ) +
  scale_fill_brewer(palette="Paired") + 
  labs(title = "Credit limit per closure status", x = "Closure status",
       y = "credit_limit") +
  theme(plot.title=element_text(hjust=0.5))

```



# Question 5


**Question**:
 Is there a particular section of people who are majority in closed status category ?

**Answer**:
The below scatter plot grid shows the cross section of credit_limit, income, employment status and dependents. The concentration of people who closed their accounts is more where they have 3 dependent, doing a part time job and having credit limit below 10,000. The least people are present in self employed category.

```{r}
#Visualization
ggplot(data = credit_card_df_closed, mapping = aes(x = income, y = credit_limit, color = employment_status)) +
       geom_point() + 
       facet_grid(employment_status ~ dependents) +
       labs(title = "Credit limit vs Income with dependents and employement status") +
       theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),plot.title=element_text(hjust=0.5))


```




# Machine Learning


In this section of the project, you will fit **three classification algorithms** to predict the outcome variable,`customer_status`.

You must follow the machine learning steps below. 

The data splitting and feature engineering steps should only be done once so that your models are using the same data and feature engineering steps for training.

- Split the `credit_card_df` data into a training and test set (remember to set your seed)
- Specify a feature engineering pipeline with the `recipes` package
    - You can include steps such as skewness transformation, correlation filters, dummy variable encoding or any other steps you find appropriate
- Specify a `parsnip` model object
    - You may choose from the following classification algorithms:
      - Logistic Regression
      - LDA
      - QDA
      - KNN
      - Decision Tree
      - Random Forest
- Package your recipe and model into a workflow
- Fit your workflow to the training data
    - If your model has hyperparameters:
      - Split the training data into 5 folds for 5-fold cross validation using `vfold_cv` (remember to set your seed)
      - Perform hyperparamter tuning with a random grid search using the `grid_random()` function
      - Refer to the following tutorial for an example - [Random Grid Search](https://gmubusinessanalytics.netlify.app/lesson-08-r-tutorial.html#Hyperparameter_Tuning14){target="_blank"}
      - Hyperparameter tuning can take a significant amount of computing time. Be careful not to set the `size` argument of `grid_random()` too large. I recommend `size` = 10 or smaller.
      - Select the best model with `select_best()` and finalize your workflow
- Evaluate model performance on the test set by plotting an ROC curve using `autoplot()` and calculating the area under the ROC curve on your test data




# Model 1

```{r}

# Logistic Regresssion
#Data Splilitting.

head(credit_card_df)
set.seed(273)

credit_card_df_split <- initial_split(credit_card_df, prop = 0.75,
                              strata = customer_status)

credit_card_df_training <- credit_card_df_split %>% 
                   training()

credit_card_df_testing <- credit_card_df_split %>%
               testing()


# Create cross validation folds for hyperparameter tuning
set.seed(278)

credit_card_df_folds <- vfold_cv(credit_card_df_training, v = 5)

# Feature Engineering

credit_card_df_recipe <- recipe(customer_status ~ ., data = credit_card_df_training) %>% 
                 step_YeoJohnson(all_numeric(), -all_outcomes()) %>% 
                 step_normalize(all_numeric(), -all_outcomes()) %>% 
                 step_dummy(all_nominal(), -all_outcomes())


credit_card_df_recipe %>% 
  prep(training = credit_card_df_training) %>% 
  bake(new_data = NULL)

#Specify Logistic Regression Model. 
logistic_model <- logistic_reg() %>% 
                  set_engine('glm') %>% 
                  set_mode('classification')


# Creating Workflow.
logistic_wf <- workflow() %>% 
               add_model(logistic_model) %>% 
               add_recipe(credit_card_df_recipe)

#Fitting model
logistic_fit <- logistic_wf %>% 
                last_fit(split = credit_card_df_split)

# Collecting predictions.
logistic_results <-  logistic_fit %>% 
                     collect_predictions()
logistic_results

# Evaluating Performance

## ROC Curve
roc_curve(logistic_results, 
          truth = customer_status, 
          estimate = .pred_closed_account) %>% 
  autoplot()

# ROC AUC
roc_auc(logistic_results, 
        truth = customer_status,
        .pred_closed_account)

# Confusion matrix 
conf_mat(logistic_results, 
         truth = customer_status, 
         estimate = .pred_class)

#Accuracy, sensitivity and specificity.
custom_metrics_logistic <- metric_set(accuracy, sens, spec, roc_auc)
custom_metrics_logistic(logistic_results, 
         truth = customer_status, 
         estimate = .pred_class, .pred_closed_account )

```

# Model 2

```{r}
# Linear Discriminate Analysis
library(rsample)
library(tidyverse)
library(discrim)
library(MASS)
library(klaR)

#LDA Model 
lda_model <- discrim_regularized(frac_common_cov = 1) %>% 
             set_engine('klaR') %>% 
             set_mode('classification') 


# Creating workflow 
lda_wf <- workflow() %>% 
          add_model(lda_model) %>% 
          add_recipe(credit_card_df_recipe)

#Fit Model
lda_fit <- lda_wf %>% 
           last_fit(split = credit_card_df_split)

# Collect Predictions
lda_results <-  lda_fit %>% 
                collect_predictions()

## ROC Curve
roc_curve(lda_results, 
          truth = customer_status,
        .pred_closed_account) %>% 
  autoplot()

# ROC AUC
roc_auc(lda_results, 
        truth = customer_status,
        .pred_closed_account)

# Confusion Matrix
conf_mat(lda_results, 
         truth = customer_status, 
         estimate = .pred_class)

#Accuracy, sensitivity and specificity.
custom_metrics_lda <- metric_set(accuracy, sens, spec, roc_auc)
custom_metrics_lda(lda_results, 
         truth = customer_status, 
         estimate = .pred_class, .pred_closed_account)


```


# Model 3

```{r}
#Decision trees
library(vip)
library(rpart)
library(rpart.plot)

set.seed(316)

#Using the split and feature engineering mentioned above in Logistic regression
tree_model <- decision_tree(cost_complexity = tune(), tree_depth = tune(), min_n = tune()) %>%
              set_engine('rpart') %>% 
              set_mode('classification')

#Workflow
tree_workflow <- workflow() %>% 
                 add_model(tree_model) %>% 
                 add_recipe(credit_card_df_recipe)

## Create a grid of hyperparameter values to test
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          min_n(), 
                          levels = 2)
#View grid
tree_grid

# Alternate way tuning grids
tree_grid <- grid_regular(parameters(tree_model), 
                          levels = 2)

tree_grid

## Tune decision tree workflow
set.seed(314)

tree_tuning <- tree_workflow %>% 
               tune_grid(resamples = credit_card_df_folds,
                         grid = tree_grid)

## Show the top 5 best models based on roc_auc metric
tree_tuning %>% show_best('roc_auc')

## Select best model based on roc_auc
best_tree <- tree_tuning %>% 
             select_best(metric = 'roc_auc')

# View the best tree parameters
best_tree

#Finalize the work flow
final_tree_workflow <- tree_workflow %>% 
                       finalize_workflow(best_tree)

#Fitting the best model 
tree_wf_fit <- final_tree_workflow %>% 
               fit(data = credit_card_df_training)


tree_fit <- tree_wf_fit %>% 
            extract_fit_parsnip()

vip(tree_fit)

# Plotting the tree
rpart.plot(tree_fit$fit, roundint = FALSE, extra = 2)

#Training and evaluating with last fit
tree_last_fit <- final_tree_workflow %>% 
                 last_fit(credit_card_df_split)

tree_last_fit %>% collect_metrics()

#ROC curve 
tree_last_fit %>% collect_predictions() %>% 
                  roc_curve(truth  = customer_status, estimate = .pred_closed_account) %>% 
                  autoplot()


# Confusion matrix
tree_predictions <- tree_last_fit %>% collect_predictions()

conf_mat(tree_predictions, truth = customer_status, estimate = .pred_class)

#accuracy, Sensitivity and specification.
custom_metrics_tree <- metric_set(accuracy, sens, spec, roc_auc)
custom_metrics_tree(tree_predictions, truth = customer_status, estimate = .pred_class, .pred_closed_account)


```




# Summary of Results

Write a summary of your overall findings and recommendations to the executives at the bank. Think of this section as your closing remarks of a presentation, where you summarize your key findings, model performance, and make recommendations to improve customer retention and service at the bank.

Your executive summary must be written in a [professional tone](https://www.universalclass.com/articles/writing/business-writing/appropriate-tone-in-business-communications.htm){target="_blank"}, with minimal grammatical errors, and should include the following sections:

1. An introduction where you explain the business problem and goals of your data analysis

    - What problem(s) is this company trying to solve? Why are they important to their future success?
  
    - What was the goal of your analysis? What questions were you trying to answer and why do they matter?

<br>

2. Highlights and key findings from your Exploratory Data Analysis section 
    - What were the interesting findings from your analysis and **why are they important for the business**?

    - This section is meant to **establish the need for your recommendations** in the following section

<br>

3. Your “best” classification model and an analysis of its performance 
    - In this section you should talk about the expected error of your model on future data
      - To estimate future performance, you can use your model performance results on the **test data**
    - You should discuss at least one performance metric, such as an F1, sensitivity, specificity, or ROC AUC for your model. However, you must explain the results in an **intuitive, non-technical manner**. Your audience in this case are executives at a bank with limited knowledge of machine learning.

<br>

4. Your recommendations to the bank on how to reduce the number of customers closing their credit card accounts 
  
    - Each recommendation must be supported by your data analysis results 

    - You must clearly explain why you are making each recommendation and which results from your data analysis support this recommendation

    - You must also describe the potential business impact of your recommendation:
      
      - Why is this a good recommendation? 
      
      - What benefits will the business achieve?


**Summary**

Add your summary here. Please do not place your text within R code chunks.

To minimize financial losses, the bank aims to be better able to identify customers at risk of cancelling their accounts. Customers have closed their credit accounts in record numbers over the past couple of years, leading to declining revenue. The banks must maintain profits by maximizing the number of credit lines they provide to their customers. It is also in their best interest to encourage their customers to carry large credit card balances from month to month to maximize interest earnings. We are trying to determine what contributes to customers cancelling their credit card accounts and whether the bank can predict whether a customer will do the same in the future.
I have identified below questions for analysis: - 
a)	Does last year transactions effect the customer status.
b)	Does last year spending make any difference in account.
c)	Does number of dependents effect the people who have closed the account.
d)	Is credit limit affecting the closure status?
e)	Is there a particular section of people who are majority in closed status category?
These questions are important to identify what the causes for are closing the account and predict based on some condition whether a person will be closing the account or not. 

Key findings from exploratory analysis are: -
The average transactions made last year is higher for active status class than closed status class. This means people who made more transactions are more likely to maintain active status.The average spendings made last year is higher for active status class than closed status class. This means people who made more spendings are more likely to maintain active status. We can see there are most people having 3 dependents in the closed account category followed by people having 2 dependents. This means that having more dependents might not be the reason for a person to close the account. We can see that credit limit is high for active accounts when compared to closed accounts. Similarly, active accounts have higher median value when compared to closed accounts. We can infer that higher credit limits will impact closure status of a person. The concentration of people who closed their accounts is more where they have 3 dependents, doing a part time job and having credit limit below 10,000. The least people are present in self-employed category. The credit limit, employment status effect the account status of the person. Based on these findings, we can identify the factors causing people to close accounts.  Knowing the causes helps us discover ways to reduce the closures.

The three models which I used are Logistic regression, LDA (Linear Discriminate Analysis), and Decision trees. Out of the three models, Decision tree gave te most optimal results while predicting on Test data. The statement is based on the 3-performance metrics b) Sensitivity c) Specificity. 
a)	Accuracy: - It gives us the proportion of correctly classified rows in the data. 
b)	Sensitivity: - Proportion of all positive classes that were correctly classified
c)	Specificity: - Proportion of all negative cases that were correctly classified.
Now all these are highest for Decision tree model with an accuracy = 90.492, Sensitivity = 88.336, Specificity = 92.27. What its states is this model (Decision tree) most efficiently identifies or predicts whether the person is going to close the account or keep it. This is because, the decision tree model identifies positive classes and negative most efficiently (as given from sensitivity and specificity values).

My recommendations would be: - 
To keep increasing the transactions done by an individual, increasing different modes of transactions helps as the user has many things to choose from. Similarly, to increase the amount of money spent by person, offering discounts and perks like cashbacks will help in increasing the spending of a person. Majority of closed accounts are happening in the case of part time employees. So, to sustain them, they need to be special perks like low interest rates on credit amount, increasing the length of repayment period etc. Increasing the credit limit without any background analysis of individual will lead to errors in assessing a credit payment capability of a person. So, while increasing credit limit, background details like utilization ratio, spent ratio, age, martial etc. need to be considered so that it gives better understanding of social, personal and economic conditions.




